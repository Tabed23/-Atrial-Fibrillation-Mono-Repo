{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "400c2cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import essential libraries\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a88fbf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1803, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ritmi</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>heart_axis</th>\n",
       "      <th>validated_by</th>\n",
       "      <th>second_opinion</th>\n",
       "      <th>validated_by_human</th>\n",
       "      <th>pacemaker</th>\n",
       "      <th>strat_fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>164.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1</td>\n",
       "      <td>152.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ritmi   age  sex  height  weight  heart_axis  validated_by  second_opinion  \\\n",
       "0      2  29.0    1   164.0    56.0           0           0.0               0   \n",
       "1      0  59.0    0   156.0    75.0           0           0.0               0   \n",
       "2      2  84.0    1   152.0    51.0           0           0.0               0   \n",
       "3      0  79.0    0   172.0    66.0           0           0.0               0   \n",
       "4      1  67.0    0   178.0    73.0           4           0.0               0   \n",
       "\n",
       "   validated_by_human  pacemaker  strat_fold  \n",
       "0                   1          0           1  \n",
       "1                   1          0           9  \n",
       "2                   1          0           7  \n",
       "3                   1          0           5  \n",
       "4                   1          0           5  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# read in csv \n",
    "df = pd.read_csv('training_11_features.csv')\n",
    "df = df.dropna()\n",
    "# df = df[df['ritmi'] != 0]\n",
    "df = df.reset_index(drop=True)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7a0d7ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1803 entries, 0 to 1802\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count  Dtype\n",
      "---  ------              --------------  -----\n",
      " 0   ritmi               1803 non-null   int64\n",
      " 1   age                 1803 non-null   int64\n",
      " 2   sex                 1803 non-null   int64\n",
      " 3   height              1803 non-null   int64\n",
      " 4   weight              1803 non-null   int64\n",
      " 5   heart_axis          1803 non-null   int64\n",
      " 6   validated_by        1803 non-null   int64\n",
      " 7   second_opinion      1803 non-null   int64\n",
      " 8   validated_by_human  1803 non-null   int64\n",
      " 9   pacemaker           1803 non-null   int64\n",
      " 10  strat_fold          1803 non-null   int64\n",
      "dtypes: int64(11)\n",
      "memory usage: 155.1 KB\n"
     ]
    }
   ],
   "source": [
    "# convert all columns' types to int64\n",
    "df['age'] = df['age'].astype('int64')\n",
    "df['height'] = df['height'].astype('int64')\n",
    "df['weight'] = df['weight'].astype('int64')\n",
    "df['validated_by'] = df['validated_by'].astype('int64')\n",
    "\n",
    "# get info for columns\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "41093052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "X = df.drop(columns='ritmi')\n",
    "y = df['ritmi']\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size = 0.25, random_state = 246)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4d944d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "feb4c180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:0.46596640899829833\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 60, 'n_estimators': 600}\n"
     ]
    }
   ],
   "source": [
    "# Plug in appropriate max_depth and random_state parameters\n",
    "rf = RandomForestClassifier()\n",
    "rf_param_grid = {'n_estimators': [600], 'criterion': ['entropy'], 'max_depth': [60]} #0.4615443314230772\n",
    "\n",
    "rf_cv= GridSearchCV(rf,rf_param_grid,cv=7,n_jobs=-1)\n",
    "\n",
    "rf_cv.fit(X_train,y_train)\n",
    "\n",
    "print(\"Best Score:\" + str(rf_cv.best_score_))\n",
    "print(\"Best Parameters: \" + str(rf_cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7de8a8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.47      0.47       162\n",
      "           1       0.46      0.43      0.44       117\n",
      "           2       0.46      0.48      0.47       172\n",
      "\n",
      "    accuracy                           0.46       451\n",
      "   macro avg       0.46      0.46      0.46       451\n",
      "weighted avg       0.46      0.46      0.46       451\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf_cv.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8ab754d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c683d5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "KNeighborsClassifier(metric='euclidean', n_neighbors=150, weights='distance') {'metric': 'euclidean', 'n_neighbors': 150, 'weights': 'distance'} 0.4881918819188192\n"
     ]
    }
   ],
   "source": [
    "clfl2 = KNeighborsClassifier()\n",
    "parameters = {'n_neighbors': [150], 'weights': ['distance'], 'metric': ['euclidean']} #0.4889326226595599\n",
    "\n",
    "fitmodel = GridSearchCV(clfl2, param_grid=parameters, cv=5, refit=True, scoring=\"accuracy\", n_jobs=-1, verbose=3)\n",
    "fitmodel.fit(X_train, y_train)\n",
    "print(fitmodel.best_estimator_, fitmodel.best_params_, fitmodel.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "41755e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.40      0.43       162\n",
      "           1       0.49      0.47      0.48       117\n",
      "           2       0.43      0.50      0.46       172\n",
      "\n",
      "    accuracy                           0.46       451\n",
      "   macro avg       0.46      0.46      0.46       451\n",
      "weighted avg       0.46      0.46      0.46       451\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = fitmodel.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ff42a2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/tabeedhassan/.local/lib/python3.8/site-packages (2.10.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/tabeedhassan/.local/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in /home/tabeedhassan/.local/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/tabeedhassan/.local/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/tabeedhassan/.local/lib/python3.8/site-packages (from tensorflow) (4.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/tabeedhassan/.local/lib/python3.8/site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (45.2.0)\n",
      "Requirement already satisfied: packaging in /home/tabeedhassan/.local/lib/python3.8/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/tabeedhassan/.local/lib/python3.8/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/tabeedhassan/.local/lib/python3.8/site-packages (from tensorflow) (1.23.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/tabeedhassan/.local/lib/python3.8/site-packages (from tensorflow) (1.47.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in /home/tabeedhassan/.local/lib/python3.8/site-packages (from tensorflow) (2.10.1)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/tabeedhassan/.local/lib/python3.8/site-packages (from tensorflow) (22.10.26)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/tabeedhassan/.local/lib/python3.8/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/tabeedhassan/.local/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/tabeedhassan/.local/lib/python3.8/site-packages (from tensorflow) (0.27.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/tabeedhassan/.local/lib/python3.8/site-packages (from tensorflow) (1.3.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/tabeedhassan/.local/lib/python3.8/site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/tabeedhassan/.local/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/tabeedhassan/.local/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /home/tabeedhassan/.local/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/tabeedhassan/.local/lib/python3.8/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/tabeedhassan/.local/lib/python3.8/site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/tabeedhassan/.local/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.14.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/tabeedhassan/.local/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.34.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/tabeedhassan/.local/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/tabeedhassan/.local/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/tabeedhassan/.local/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/tabeedhassan/.local/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/tabeedhassan/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/tabeedhassan/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /home/tabeedhassan/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /home/tabeedhassan/.local/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (4.12.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/tabeedhassan/.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/tabeedhassan/.local/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/lib/python3/dist-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "#Convo1D\n",
    "!pip install  --default-timeout=100 tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b80a446a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, MaxPooling1D, Dense, Dropout, Input, Flatten, SeparableConv1D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.models import Model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.optimizers import Adam\n",
    "import math\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ce59bcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    input_img = Input(shape=(feature, depth), name='ImageInput')\n",
    "    x = Conv1D(32, 3, activation='relu', padding='same', name='Conv1_1')(input_img)\n",
    "    x = Conv1D(32, 3, activation='relu', padding='same', name='Conv1_2')(x)\n",
    "    x = MaxPooling1D(2, name='pool1')(x)\n",
    "    \n",
    "    x = SeparableConv1D(32, 3, activation='relu', padding='same', name='Conv2_1')(x)\n",
    "    x = SeparableConv1D(32, 3, activation='relu', padding='same', name='Conv2_2')(x)\n",
    "    x = MaxPooling1D(2, name='pool2')(x)\n",
    "    \n",
    "    x = SeparableConv1D(64, 3, activation='relu', padding='same', name='Conv3_1')(x)\n",
    "    x = BatchNormalization(name='bn1')(x)\n",
    "    x = SeparableConv1D(64, 3, activation='relu', padding='same', name='Conv3_2')(x)\n",
    "    x = BatchNormalization(name='bn2')(x)\n",
    "    \n",
    "    x = SeparableConv1D(64, 3, activation='relu', padding='same', name='Conv3_3')(x)\n",
    "    x = MaxPooling1D(2, name='pool3')(x)\n",
    "    \n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(128, activation='relu', name='fc1')(x)\n",
    "    x = Dropout(0.6, name='dropout1')(x)\n",
    "    x = Dense(128, activation='relu', name='fc2')(x)\n",
    "    x = Dropout(0.5, name='dropout2')(x)\n",
    "    x = Dense(5, activation='softmax', name='fc3')(x)\n",
    "    \n",
    "    model = Model(inputs=input_img, outputs=x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0f96846a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (1352, 10)\n",
      "y_train (1352,)\n",
      "X_test (451, 10)\n",
      "y_test (451,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train\", X_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print(\"X_test\", X_test.shape)\n",
    "print(\"y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "00b80a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_obs ,feature = X_train.shape\n",
    "depth = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "cc96688f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ImageInput (InputLayer)     [(None, 10, 1)]           0         \n",
      "                                                                 \n",
      " Conv1_1 (Conv1D)            (None, 10, 32)            128       \n",
      "                                                                 \n",
      " Conv1_2 (Conv1D)            (None, 10, 32)            3104      \n",
      "                                                                 \n",
      " pool1 (MaxPooling1D)        (None, 5, 32)             0         \n",
      "                                                                 \n",
      " Conv2_1 (SeparableConv1D)   (None, 5, 32)             1152      \n",
      "                                                                 \n",
      " Conv2_2 (SeparableConv1D)   (None, 5, 32)             1152      \n",
      "                                                                 \n",
      " pool2 (MaxPooling1D)        (None, 2, 32)             0         \n",
      "                                                                 \n",
      " Conv3_1 (SeparableConv1D)   (None, 2, 64)             2208      \n",
      "                                                                 \n",
      " bn1 (BatchNormalization)    (None, 2, 64)             256       \n",
      "                                                                 \n",
      " Conv3_2 (SeparableConv1D)   (None, 2, 64)             4352      \n",
      "                                                                 \n",
      " bn2 (BatchNormalization)    (None, 2, 64)             256       \n",
      "                                                                 \n",
      " Conv3_3 (SeparableConv1D)   (None, 2, 64)             4352      \n",
      "                                                                 \n",
      " pool3 (MaxPooling1D)        (None, 1, 64)             0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 128)               8320      \n",
      "                                                                 \n",
      " dropout1 (Dropout)          (None, 128)               0         \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout2 (Dropout)          (None, 128)               0         \n",
      "                                                                 \n",
      " fc3 (Dense)                 (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,437\n",
      "Trainable params: 42,181\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model =  build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "a7cadc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr = 0.001, beta_1 = 0.9, beta_2 = 0.999)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "593fbb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_decay(epoch):\n",
    "    initial_lrate = 0.001\n",
    "    k = 0.75\n",
    "    t = n_obs//(10000 * batch_size)  # every epoch we do n_obs/batch_size iteration\n",
    "    lrate = initial_lrate * math.exp(-k*t)\n",
    "    return lrate\n",
    "\n",
    "lrate = LearningRateScheduler(exp_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "87b8248f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/tabeedhassan/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/tabeedhassan/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/tabeedhassan/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/tabeedhassan/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/tabeedhassan/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"/home/tabeedhassan/.local/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/tabeedhassan/.local/lib/python3.8/site-packages/keras/losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/tabeedhassan/.local/lib/python3.8/site-packages/keras/losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/tabeedhassan/.local/lib/python3.8/site-packages/keras/losses.py\", line 1990, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/home/tabeedhassan/.local/lib/python3.8/site-packages/keras/backend.py\", line 5529, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 5) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [155]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m75\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlrate\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filey7j_uvpd.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/tabeedhassan/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/tabeedhassan/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/tabeedhassan/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/tabeedhassan/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/tabeedhassan/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"/home/tabeedhassan/.local/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/tabeedhassan/.local/lib/python3.8/site-packages/keras/losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/tabeedhassan/.local/lib/python3.8/site-packages/keras/losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/tabeedhassan/.local/lib/python3.8/site-packages/keras/losses.py\", line 1990, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/home/tabeedhassan/.local/lib/python3.8/site-packages/keras/backend.py\", line 5529, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 5) are incompatible\n"
     ]
    }
   ],
   "source": [
    "batch_size = 500\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=75, \n",
    "                    batch_size=batch_size, \n",
    "                    verbose=2, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    callbacks=[lrate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c20e75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
